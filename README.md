# âš¡ Kafka Cluster with Docker Compose

This project sets up an **Apache Kafka** cluster using Docker and Docker Compose. The cluster consists of multiple **controllers** and **brokers** to demonstrate the use of Kafka in a production-like environment with fault tolerance and scalability. It also includes examples of how to connect to Kafka from a Python application to send messages to a client.

## ğŸ“‚ Project Structure

- **Controllers**: ğŸ› ï¸ Handle Kafka metadata and leader election (**KRaft mode**).
- **Brokers**: ğŸ—„ï¸ Store data (messages) and handle client requests for message production and consumption.

## âœ¨ Features

- ğŸ–¥ï¸ **Multiple Controllers**: 3 Kafka controllers (`controller-1`, `controller-2`, `controller-3`) for high availability.
- ğŸ“Š **Multiple Brokers**: 3 Kafka brokers (`broker-1`, `broker-2`, `broker-3`) to distribute and store messages.
- ğŸ³ **Dockerized Setup**: Easily start the entire cluster using Docker Compose.
- ğŸ **Python Kafka Producer Example**: Simple Python script to send messages to Kafka.

## ğŸ“‹ Prerequisites

Ensure you have the following installed:

- [Docker](https://www.docker.com/get-started) ğŸ³
- [Docker Compose](https://docs.docker.com/compose/install/) ğŸ™
- [Python 3.6+](https://www.python.org/downloads/) ğŸ

## ğŸš€ Getting Started

### Step 1: Clone the Repository

```bash
git clone https://github.com/yourusername/kafka-docker-cluster.git
cd kafka-docker-cluster
